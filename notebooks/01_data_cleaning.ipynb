{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-commerce Data Cleaning and Preprocessing\n",
    "\n",
    "This notebook focuses on cleaning and preparing the e-commerce dataset for analysis. We'll perform:\n",
    "1. Data loading and initial inspection\n",
    "2. Handling missing values\n",
    "3. Removing duplicates\n",
    "4. Handling outliers\n",
    "5. Data validation\n",
    "6. Saving cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_processing import DataProcessor\n",
    "from src.config import RAW_DATA_DIR, PROCESSED_DATA_DIR\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the raw data\n",
    "raw_data = pd.read_csv(RAW_DATA_DIR / 'sales_data.csv')\n",
    "print(f\"Dataset shape: {raw_data.shape}\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data info and statistics\n",
    "print(\"\\nDataset Info:\")\n",
    "raw_data.info()\n",
    "\n",
    "print(\"\\nBasic Statistics:\")\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize data processor\n",
    "processor = DataProcessor(raw_data)\n",
    "\n",
    "# Check missing values\n",
    "missing_values = processor.check_missing_values()\n",
    "print(\"Missing values percentage:\")\n",
    "for col, pct in missing_values.items():\n",
    "    if pct > 0:\n",
    "        print(f\"{col}: {pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define imputation strategy\n",
    "imputation_strategy = {\n",
    "    'price': 'median',\n",
    "    'quantity': 'median',\n",
    "    'customer_id': 'drop',\n",
    "    'product_id': 'drop',\n",
    "    'category': 'mode'\n",
    "}\n",
    "\n",
    "# Apply imputation\n",
    "cleaned_data = processor.handle_missing_values(imputation_strategy)\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(cleaned_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for duplicates\n",
    "duplicate_count = cleaned_data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Remove duplicates\n",
    "cleaned_data = processor.handle_duplicates()\n",
    "print(f\"Shape after removing duplicates: {cleaned_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize numerical distributions\n",
    "numerical_cols = ['price', 'quantity']\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    sns.boxplot(data=cleaned_data, y=col, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Handle outliers\n",
    "cleaned_data = processor.handle_outliers(\n",
    "    columns=['price', 'quantity'],\n",
    "    method='iqr',\n",
    "    threshold=1.5\n",
    ")\n",
    "\n",
    "print(f\"Shape after handling outliers: {cleaned_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert date columns\n",
    "cleaned_data = processor.format_dates(['order_date'])\n",
    "print(\"\\nDate column info:\")\n",
    "print(cleaned_data['order_date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Perform validation checks\n",
    "validation_results = processor.validate_data()\n",
    "\n",
    "print(\"Validation Results:\")\n",
    "for check, result in validation_results.items():\n",
    "    print(f\"{check}: {'Passed' if not result else 'Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save processed data\n",
    "output_path = PROCESSED_DATA_DIR / 'cleaned_sales_data.csv'\n",
    "cleaned_data.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned data saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}
