{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-commerce Sales Forecasting Analysis\n",
    "\n",
    "This notebook focuses on building and evaluating sales forecasting models:\n",
    "1. Data Preparation for Time Series Analysis\n",
    "2. Time Series Decomposition\n",
    "3. Model Building\n",
    "    - Simple Moving Average\n",
    "    - Exponential Smoothing\n",
    "    - SARIMA Model\n",
    "4. Model Evaluation\n",
    "5. Future Sales Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.model_utils import ModelUtils\n",
    "from src.config import PROCESSED_DATA_DIR\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_csv(PROCESSED_DATA_DIR / 'cleaned_sales_data.csv')\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "# Create daily sales time series\n",
    "daily_sales = df.groupby('order_date')['price'].sum().reset_index()\n",
    "daily_sales.set_index('order_date', inplace=True)\n",
    "\n",
    "# Fill missing dates with zero sales\n",
    "idx = pd.date_range(daily_sales.index.min(), daily_sales.index.max())\n",
    "daily_sales = daily_sales.reindex(idx, fill_value=0)\n",
    "\n",
    "print(\"Time series information:\")\n",
    "print(f\"Start date: {daily_sales.index.min()}\")\n",
    "print(f\"End date: {daily_sales.index.max()}\")\n",
    "print(f\"Total days: {len(daily_sales)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Perform time series decomposition\n",
    "decomposition = seasonal_decompose(daily_sales['price'], period=7)\n",
    "\n",
    "# Plot decomposition\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(daily_sales.index, daily_sales['price'])\n",
    "plt.title('Original Time Series')\n",
    "\n",
    "plt.subplot(412)\n",
    "plt.plot(daily_sales.index, decomposition.trend)\n",
    "plt.title('Trend')\n",
    "\n",
    "plt.subplot(413)\n",
    "plt.plot(daily_sales.index, decomposition.seasonal)\n",
    "plt.title('Seasonal')\n",
    "\n",
    "plt.subplot(414)\n",
    "plt.plot(daily_sales.index, decomposition.resid)\n",
    "plt.title('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split data into train and test sets\n",
    "train_size = int(len(daily_sales) * 0.8)\n",
    "train_data = daily_sales[:train_size]\n",
    "test_data = daily_sales[train_size:]\n",
    "\n",
    "print(f\"Training set size: {len(train_data)} days\")\n",
    "print(f\"Test set size: {len(test_data)} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Simple Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_moving_average(data, window):\n",
    "    \"\"\"Calculate moving average predictions\"\"\"\n",
    "    return data.rolling(window=window).mean()\n",
    "\n",
    "# Calculate 7-day moving average\n",
    "ma_predictions = calculate_moving_average(train_data['price'], 7)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_data.index, train_data['price'], label='Actual')\n",
    "plt.plot(train_data.index, ma_predictions, label='7-day MA')\n",
    "plt.title('Simple Moving Average Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Fit Holt-Winters model\n",
    "hw_model = ExponentialSmoothing(\n",
    "    train_data['price'],\n",
    "    seasonal_periods=7,\n",
    "    trend='add',\n",
    "    seasonal='add'\n",
    ")\n",
    "hw_results = hw_model.fit()\n",
    "\n",
    "# Generate predictions\n",
    "hw_predictions = hw_results.forecast(len(test_data))\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_data.index, train_data['price'], label='Training Data')\n",
    "plt.plot(test_data.index, test_data['price'], label='Actual')\n",
    "plt.plot(test_data.index, hw_predictions, label='Holt-Winters')\n",
    "plt.title('Holt-Winters Exponential Smoothing Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Fit SARIMA model\n",
    "sarima_model = SARIMAX(\n",
    "    train_data['price'],\n",
    "    order=(1, 1, 1),\n",
    "    seasonal_order=(1, 1, 1, 7)\n",
    ")\n",
    "sarima_results = sarima_model.fit()\n",
    "\n",
    "# Generate predictions\n",
    "sarima_predictions = sarima_results.forecast(len(test_data))\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_data.index, train_data['price'], label='Training Data')\n",
    "plt.plot(test_data.index, test_data['price'], label='Actual')\n",
    "plt.plot(test_data.index, sarima_predictions, label='SARIMA')\n",
    "plt.title('SARIMA Model Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_metrics(actual, predicted):\n",
    "    \"\"\"Calculate error metrics\"\"\"\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "    return mae, rmse, mape\n",
    "\n",
    "# Calculate metrics for each model\n",
    "hw_mae, hw_rmse, hw_mape = calculate_metrics(\n",
    "    test_data['price'], \n",
    "    hw_predictions\n",
    ")\n",
    "\n",
    "sarima_mae, sarima_rmse, sarima_mape = calculate_metrics(\n",
    "    test_data['price'], \n",
    "    sarima_predictions\n",
    ")\n",
    "\n",
    "# Create comparison table\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['Holt-Winters', 'SARIMA'],\n",
    "    'MAE': [hw_mae, sarima_mae],\n",
    "    'RMSE': [hw_rmse, sarima_rmse],\n",
    "    'MAPE': [hw_mape, sarima_mape]\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Future Sales Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate future predictions using the best performing model\n",
    "future_periods = 30  # Forecast next 30 days\n",
    "\n",
    "# Use Holt-Winters model for final predictions\n",
    "final_model = ExponentialSmoothing(\n",
    "    daily_sales['price'],\n",
    "    seasonal_periods=7,\n",
    "    trend='add',\n",
    "    seasonal='add'\n",
    ")\n",
    "final_results = final_model.fit()\n",
    "\n",
    "# Generate future dates\n",
    "last_date = daily_sales.index[-1]\n",
    "future_dates = pd.date_range(\n",
    "    start=last_date + pd.Timedelta(days=1),\n",
    "    periods=future_periods\n",
    ")\n",
    "\n",
    "# Generate predictions\n",
    "future_predictions = final_results.forecast(future_periods)\n",
    "\n",
    "# Plot final forecast\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(daily_sales.index, daily_sales['price'], label='Historical Data')\n",
    "plt.plot(future_dates, future_predictions, label='Forecast', linestyle='--')\n",
    "plt.title('30-Day Sales Forecast')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create forecast summary\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Date': future_dates,\n",
    "    'Predicted_Sales': future_predictions\n",
    "})\n",
    "\n",
    "print(\"\\nForecast Summary:\")\n",
    "print(f\"Total Predicted Sales: ${forecast_df['Predicted_Sales'].sum():,.2f}\")\n",
    "print(f\"Average Daily Sales: ${forecast_df['Predicted_Sales'].mean():,.2f}\")\n",
    "print(f\"Peak Sales Day: {forecast_df.loc[forecast_df['Predicted_Sales'].idxmax(), 'Date'].strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save forecast results\n",
    "forecast_df.to_csv(PROCESSED_DATA_DIR / 'sales_forecast.csv', index=False)\n",
    "\n",
    "# Save model performance metrics\n",
    "metrics_df.to_csv(PROCESSED_DATA_DIR / 'model_metrics.csv', index=False)\n",
    "\n",
    "print(\"Forecast results and model metrics saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}
